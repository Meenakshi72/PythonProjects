{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meenakshi72/PythonProjects/blob/main/Tweet_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NC5dNYPoPQcz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re #regular expression\n",
        "import string\n",
        "import nltk \n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Twitter Sentiments.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "lwZSn7scp2Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "kQBqUmYsqS7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_pattern(input_txt, pattern):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for word in r:\n",
        "        input_txt = re.sub(word, \"\", input_txt)\n",
        "    return input_txt"
      ],
      "metadata": {
        "id": "r1k9POwLqS9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_tweet'] = np.vectorize(remove_pattern)(df['tweet'], \"@[\\w]*\")"
      ],
      "metadata": {
        "id": "anZ0m5wVtAFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "C95LQks5tAHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove special characters, numbers and punctuations\n",
        "df['clean_tweet'] = df['clean_tweet'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "RN5_-MmFtANG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: \" \".join([w for w in x.split() if len(w)>3]))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "B6yWhKwEtAPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_tweet = df['clean_tweet'].apply(lambda x: x.split())\n",
        "tokenized_tweet.head()"
      ],
      "metadata": {
        "id": "MA-jIHq7tcdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "tokenized_tweet = tokenized_tweet.apply(lambda sentence: [stemmer.stem(word) for word in sentence])\n",
        "tokenized_tweet.head()"
      ],
      "metadata": {
        "id": "5Gff87-qtcf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(tokenized_tweet)):\n",
        "    tokenized_tweet[i] = \" \".join(tokenized_tweet[i])\n",
        "    \n",
        "df['clean_tweet'] = tokenized_tweet\n",
        "df.head()"
      ],
      "metadata": {
        "id": "6Fc_cbwjtckc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wordcloud"
      ],
      "metadata": {
        "id": "VIZ8hX-Rti98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = \" \".join([sentence for sentence in df['clean_tweet']])\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "wordcloud = WordCloud(width=800, height=500, random_state=None, max_font_size= 150).generate(all_words)\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_ekvbh49tjAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = \" \".join([sentence for sentence in df['clean_tweet'][df['label']==0]])\n",
        "\n",
        "wordcloud = WordCloud(width=800, height=500, random_state=42, max_font_size=100).generate(all_words)\n",
        "\n",
        "# plot the graph\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w0ORRFbWtjDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = \" \".join([sentence for sentence in df['clean_tweet'][df['label']==1]])\n",
        "\n",
        "wordcloud = WordCloud(width=800, height=500, random_state=0, max_font_size=100).generate(all_words)\n",
        "\n",
        "# plot the graph\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7B-HuBHetjFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(bow, df['label'], random_state=42, test_size=0.25)"
      ],
      "metadata": {
        "id": "4c4qPJDxtp3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "predLI = model.predict(x_test)                           #Linear Regression\n",
        "accuracy_score(y_test,predLI)"
      ],
      "metadata": {
        "id": "mSoZf3Istp5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "BNBmodel = BernoulliNB()\n",
        "BNBmodel.fit(x_train, y_train)\n",
        "predBNB = BNBmodel.predict(x_test)\n",
        "f1_score(y_test, predBNB)                               #Naive Bayes Bernoulli \n",
        "accuracy_score(y_test,predBNB)"
      ],
      "metadata": {
        "id": "icm7VWjOSCrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "Smodel = LinearSVC()\n",
        "Smodel.fit(x_train,y_train)\n",
        "predSVC = Smodel.predict(x_test)\n",
        "f1_score(y_test, predSVC)                               # Linear Support Vector machine\n",
        "accuracy_score(y_test,predSVC)"
      ],
      "metadata": {
        "id": "YkvU3ZNVSkza"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}