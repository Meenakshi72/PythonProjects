{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meenakshi72/PythonProjects/blob/main/Information_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow_text\n",
        "!pip install -q simpleneighbors[annoy]\n",
        "!pip install -q nltk\n",
        "!pip install -q tqdm"
      ],
      "metadata": {
        "id": "RRNyq1DoJIS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import nltk\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import simpleneighbors\n",
        "import urllib\n",
        "from IPython.display import HTML, display\n",
        "from tqdm.notebook import tqdm\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow_text import SentencepieceTokenizer\n",
        "nltk.download('punkt')\n",
        "print('TensorFlow version: ', tf.__version__)\n",
        "print('TensorFlow Hub version: ', hub.__version__)"
      ],
      "metadata": {
        "id": "_VArn_hJKiX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squad_url = 'https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json'\n",
        "squad_json = json.load(urllib.request.urlopen(squad_url))"
      ],
      "metadata": {
        "id": "6ElgPNPNMoth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squad_json"
      ],
      "metadata": {
        "id": "3SQ5OE2pNo4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.tokenize.sent_tokenize('Computational complexity theory is a branch of the theory of computation in theoretical computer science that focuses on classifying computational problems according to their inherent difficulty, and relating those classes to each other. A computational problem is understood to be a task that is in principle amenable to being solved by a computer, which is equivalent to stating that the problem may be solved by mechanical application of mathematical steps, such as an algorithm.')"
      ],
      "metadata": {
        "id": "Xvpm0wa3O2WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_sentences(squad):\n",
        "  all_sentences = []\n",
        "  for data in squad['data']:\n",
        "    for paragraph in data['paragraphs']:\n",
        "      sentences = nltk.tokenize.sent_tokenize(paragraph['context'])\n",
        "      #print(sentences)\n",
        "      all_sentences.extend(zip(sentences, [paragraph['context']] * len(sentences)))\n",
        "  return list(set(all_sentences))"
      ],
      "metadata": {
        "id": "_j6_l-A2Nyno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = extract_sentences(squad_json)"
      ],
      "metadata": {
        "id": "EXiIqwEYPRA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentences)"
      ],
      "metadata": {
        "id": "v8IaIvn4QN-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[0:5]"
      ],
      "metadata": {
        "id": "_agiMcmtQVcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_questions_answers(squad):\n",
        "  questions_answers = []\n",
        "  for data in squad['data']:\n",
        "    for paragraph in data['paragraphs']:\n",
        "      for qas in paragraph['qas']:\n",
        "        if qas['answers']:\n",
        "          questions_answers.append((qas['question'], qas['answers'][0]['text']))\n",
        "  return list(set(questions_answers))"
      ],
      "metadata": {
        "id": "0YfsfFb7R1ZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions_answers = extract_questions_answers(squad_json)"
      ],
      "metadata": {
        "id": "zauYhrXsTFjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(questions_answers)"
      ],
      "metadata": {
        "id": "062AJXl6TKsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions_answers[0:10]"
      ],
      "metadata": {
        "id": "uGklY04NTO1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Sentence and context\\n')\n",
        "sentence = random.choice(sentences)\n",
        "print('Sentence: ')\n",
        "pprint.pprint(sentence[0])\n",
        "print('\\nContext:\\n')\n",
        "pprint.pprint(sentence[1])\n",
        "print()"
      ],
      "metadata": {
        "id": "EJusKfo3TbzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# More models: https://tfhub.dev/s?dataset=squad\n",
        "model_path = 'https://tfhub.dev/google/universal-sentence-encoder-multilingual-qa/3'\n",
        "model = hub.load(model_path)"
      ],
      "metadata": {
        "id": "UtaNIZ9kU7rX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[0][0]"
      ],
      "metadata": {
        "id": "nLPnXkr3WOru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[0][1]"
      ],
      "metadata": {
        "id": "CHUC8gkJWRs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encodings = model.signatures['response_encoder'](input = tf.constant([sentences[0][0]]),\n",
        "                                                 context = tf.constant([sentences[0][1]]))"
      ],
      "metadata": {
        "id": "qy_McOhgV5Xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(encodings['outputs'][0])"
      ],
      "metadata": {
        "id": "RHJtyvl9XJR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = simpleneighbors.SimpleNeighbors(len(encodings['outputs'][0]), metric = 'angular')"
      ],
      "metadata": {
        "id": "gR5BaU10X4dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "slices = zip(*(iter(sentences),) * batch_size)\n",
        "num_batches = int(len(sentences) / batch_size)\n",
        "num_batches"
      ],
      "metadata": {
        "id": "j4CcUATQYenU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for s in tqdm(slices, total = num_batches):\n",
        "  sentence_batch = list([r for r, c in s])\n",
        "  context_batch = list([c for r, c in s])\n",
        "  encodings = model.signatures['response_encoder'](input = tf.constant(sentence_batch), context = tf.constant(context_batch))\n",
        "  for batch_index, batch in enumerate(sentence_batch):\n",
        "    index.add_one(batch, encodings['outputs'][batch_index])\n",
        "index.build()"
      ],
      "metadata": {
        "id": "n4VYdqWeZWlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_results = 10\n",
        "question_answer = random.choice(questions_answers)\n",
        "print(question_answer)"
      ],
      "metadata": {
        "id": "_i6mcUUQicef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_results(question, answer):\n",
        "  embedding = model.signatures['question_encoder'](tf.constant([question]))['outputs'][0]\n",
        "  #print(embedding)\n",
        "  search_results = index.nearest(embedding, n = number_of_results)\n",
        "\n",
        "  formatted_result = '''\n",
        "    <p>Random question selected from SQUAD</p>\n",
        "    <p><b>%s</b></p>\n",
        "    <p>Answer:</p>\n",
        "    <p><b>%s</b></p>\n",
        "  ''' % (question, answer)\n",
        "\n",
        "  formatted_result += '<ol>'\n",
        "  for s in search_results:\n",
        "    formatted_result += '<li>'\n",
        "    formatted_result += s\n",
        "    formatted_result += '</li>'\n",
        "  formatted_result += '</ol>'\n",
        "\n",
        "  display(HTML(formatted_result))"
      ],
      "metadata": {
        "id": "-JbooyajizDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_results(question_answer[0], question_answer[1])"
      ],
      "metadata": {
        "id": "dmzBCF8qjXQV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}